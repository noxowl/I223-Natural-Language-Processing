{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "import csv\n",
    "import pprint as pp\n",
    "import graphviz\n",
    "\n",
    "pprt = pp.PrettyPrinter(indent=2)\n",
    "pprint = lambda x: pprt.pprint(x)\n",
    "\n",
    "word_dictionary_csv = \"\"\"word,pronunciation,pos,note\n",
    "い,i,X,\n",
    "お,o,N,tail\n",
    "おと,oto,N,sound\n",
    "おと,oto,V,drop\n",
    "が,ga,P,NOM\n",
    "こ,ko,N,child\n",
    "こがた,kogata,N,miniature\n",
    "し,shi,N,city\n",
    "し,shi,X, \n",
    "た,ta,A,PAST\n",
    "たい,tai,N,sea bream\n",
    "たい,tai,A,WANT\n",
    "とし,toshi,N,year\n",
    "ね,ne,V,sleep\n",
    "ねこ,neko,N,cat\n",
    "を,o,P,ACC\n",
    "会員,kaiin,N,member\n",
    "机,tsukue,N,desk\"\"\"\n",
    "\n",
    "connection_table_csv = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'い': [{'note': '', 'pos': 'X', 'pronunciation': 'i', 'word': 'い'}],\n",
      "  'お': [{'note': 'tail', 'pos': 'N', 'pronunciation': 'o', 'word': 'お'}],\n",
      "  'おと': [ {'note': 'sound', 'pos': 'N', 'pronunciation': 'oto', 'word': 'おと'},\n",
      "          {'note': 'drop', 'pos': 'V', 'pronunciation': 'oto', 'word': 'おと'}],\n",
      "  'が': [{'note': 'NOM', 'pos': 'P', 'pronunciation': 'ga', 'word': 'が'}],\n",
      "  'こ': [{'note': 'child', 'pos': 'N', 'pronunciation': 'ko', 'word': 'こ'}],\n",
      "  'こがた': [ { 'note': 'miniature',\n",
      "             'pos': 'N',\n",
      "             'pronunciation': 'kogata',\n",
      "             'word': 'こがた'}],\n",
      "  'し': [ {'note': 'city', 'pos': 'N', 'pronunciation': 'shi', 'word': 'し'},\n",
      "         {'note': ' ', 'pos': 'X', 'pronunciation': 'shi', 'word': 'し'}],\n",
      "  'た': [{'note': 'PAST', 'pos': 'A', 'pronunciation': 'ta', 'word': 'た'}],\n",
      "  'たい': [ { 'note': 'sea bream',\n",
      "            'pos': 'N',\n",
      "            'pronunciation': 'tai',\n",
      "            'word': 'たい'},\n",
      "          {'note': 'WANT', 'pos': 'A', 'pronunciation': 'tai', 'word': 'たい'}],\n",
      "  'とし': [{'note': 'year', 'pos': 'N', 'pronunciation': 'toshi', 'word': 'とし'}],\n",
      "  'ね': [{'note': 'sleep', 'pos': 'V', 'pronunciation': 'ne', 'word': 'ね'}],\n",
      "  'ねこ': [{'note': 'cat', 'pos': 'N', 'pronunciation': 'neko', 'word': 'ねこ'}],\n",
      "  'を': [{'note': 'ACC', 'pos': 'P', 'pronunciation': 'o', 'word': 'を'}],\n",
      "  '会員': [ { 'note': 'member',\n",
      "            'pos': 'N',\n",
      "            'pronunciation': 'kaiin',\n",
      "            'word': '会員'}],\n",
      "  '机': [{'note': 'desk', 'pos': 'N', 'pronunciation': 'tsukue', 'word': '机'}]}\n"
     ]
    }
   ],
   "source": [
    "WORD_TERMINUS = {'word': '', 'pos': 'TERMINUS'}\n",
    "WORD_DICT = {}\n",
    "for row in csv.DictReader(word_dictionary_csv.splitlines()):\n",
    "    try:\n",
    "        WORD_DICT[row['word']].append(row)\n",
    "    except KeyError:\n",
    "        WORD_DICT.update({row['word']: [row]})\n",
    "pprint(WORD_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "CONN_TABLE = {}\n",
    "pprint([row for row in csv.DictReader(connection_table_csv.splitlines())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Result:\n",
    "    def __init__(self, result: any, is_ok: bool):\n",
    "        self.result = result\n",
    "        self._is_ok = is_ok\n",
    "\n",
    "    def is_ok(self):\n",
    "        return self._is_ok\n",
    "    \n",
    "    def is_err(self):\n",
    "        return self._is_ok != True\n",
    "    \n",
    "    def unwrap(self) -> any:\n",
    "        if self._is_ok:\n",
    "            return self.result\n",
    "        else:\n",
    "            raise RuntimeError(\"panic while unwrap!\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Morpheme:\n",
    "    word: str\n",
    "    size: int\n",
    "    pos: str\n",
    "    raw: dict[str, str]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MorphologicalAnalyserJaSolution:\n",
    "    all: dict\n",
    "    with_all_cost: dict\n",
    "    min_cost: dict\n",
    "\n",
    "\n",
    "class MorphologicalAnalyserJa:\n",
    "    def __init__(self, _word_dict: dict, _conn_table: dict) -> None:\n",
    "        self._origin: str = ''\n",
    "        self._dict: dict = _word_dict\n",
    "        self._conn: dict = _conn_table\n",
    "        self._word_graph: dict[int, list] = {}\n",
    "    \n",
    "    def _init_input(self, _input: str) -> None:\n",
    "        self._origin = _input\n",
    "        self._init_word_graph()\n",
    "\n",
    "    def _init_word_graph(self) -> None:\n",
    "        self._word_graph = dict((i, []) for i in range(len(self._origin) + 2))\n",
    "        self._word_graph[0] = WORD_TERMINUS\n",
    "        self._word_graph[len(self._origin) + 1] = WORD_TERMINUS\n",
    "    \n",
    "    def _find_word(self, word: str) -> list[dict[str, str]]:\n",
    "        return list(next(iter(self._dict[k])) for k in list(filter(lambda x: x.startswith(word), list(self._dict.keys()))))\n",
    "    \n",
    "    def _try_add_node(self, cursor:int, data: dict) -> None:\n",
    "        data_length = len(data['word'])\n",
    "        try:\n",
    "            node = self._word_graph[cursor + 1]\n",
    "            if isinstance(node, list):\n",
    "                self._add_node(cursor, data_length, data)\n",
    "            elif data_length == 1:\n",
    "                self._add_node(cursor, data_length, data)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    def _add_node(self, cursor: int, data_length: int, data: dict) -> None:\n",
    "        self._word_graph[cursor].append(Morpheme(data['word'], data_length, data['pos'], data))\n",
    "    \n",
    "    def _find_all_solution(self) -> None:\n",
    "        for i, word in enumerate(self._origin):\n",
    "            cursor: int = i + 1\n",
    "            list(map(lambda w: self._try_add_node(cursor, w), self._find_word(word)))\n",
    "    \n",
    "    def analyse(self, _input: str) -> Result:\n",
    "        self._init_input(_input)\n",
    "        try:\n",
    "            self._find_all_solution()\n",
    "            return Result(MorphologicalAnalyserJaSolution(\n",
    "                self._word_graph, {}, {}), is_ok=True)\n",
    "        except Exception as e:\n",
    "            pprint(e)\n",
    "            return Result(None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 0: {'pos': 'TERMINUS', 'word': ''},\n",
      "  1: [ Morpheme(word='ね', size=1, pos='V', raw={'word': 'ね', 'pronunciation': 'ne', 'pos': 'V', 'note': 'sleep'}),\n",
      "       Morpheme(word='ねこ', size=2, pos='N', raw={'word': 'ねこ', 'pronunciation': 'neko', 'pos': 'N', 'note': 'cat'})],\n",
      "  2: [ Morpheme(word='こ', size=1, pos='N', raw={'word': 'こ', 'pronunciation': 'ko', 'pos': 'N', 'note': 'child'}),\n",
      "       Morpheme(word='こがた', size=3, pos='N', raw={'word': 'こがた', 'pronunciation': 'kogata', 'pos': 'N', 'note': 'miniature'})],\n",
      "  3: [ Morpheme(word='が', size=1, pos='P', raw={'word': 'が', 'pronunciation': 'ga', 'pos': 'P', 'note': 'NOM'})],\n",
      "  4: [ Morpheme(word='た', size=1, pos='A', raw={'word': 'た', 'pronunciation': 'ta', 'pos': 'A', 'note': 'PAST'}),\n",
      "       Morpheme(word='たい', size=2, pos='N', raw={'word': 'たい', 'pronunciation': 'tai', 'pos': 'N', 'note': 'sea bream'})],\n",
      "  5: [ Morpheme(word='い', size=1, pos='X', raw={'word': 'い', 'pronunciation': 'i', 'pos': 'X', 'note': ''})],\n",
      "  6: [ Morpheme(word='を', size=1, pos='P', raw={'word': 'を', 'pronunciation': 'o', 'pos': 'P', 'note': 'ACC'})],\n",
      "  7: [ Morpheme(word='お', size=1, pos='N', raw={'word': 'お', 'pronunciation': 'o', 'pos': 'N', 'note': 'tail'}),\n",
      "       Morpheme(word='おと', size=2, pos='N', raw={'word': 'おと', 'pronunciation': 'oto', 'pos': 'N', 'note': 'sound'})],\n",
      "  8: [ Morpheme(word='とし', size=2, pos='N', raw={'word': 'とし', 'pronunciation': 'toshi', 'pos': 'N', 'note': 'year'})],\n",
      "  9: [ Morpheme(word='し', size=1, pos='N', raw={'word': 'し', 'pronunciation': 'shi', 'pos': 'N', 'note': 'city'})],\n",
      "  10: [ Morpheme(word='た', size=1, pos='A', raw={'word': 'た', 'pronunciation': 'ta', 'pos': 'A', 'note': 'PAST'})],\n",
      "  11: {'pos': 'TERMINUS', 'word': ''}}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "analyser_ja: MorphologicalAnalyserJa = MorphologicalAnalyserJa(WORD_DICT, CONN_TABLE)\n",
    "input_string = \"ねこがたいをおとした\"\n",
    "solution_result: Result = analyser_ja.analyse(input_string)\n",
    "if solution_result.is_ok():\n",
    "    solution: MorphologicalAnalyserJaSolution = solution_result.unwrap()\n",
    "    pprint(solution.all)\n",
    "    pprint(solution.with_all_cost)\n",
    "    pprint(solution.min_cost)\n",
    "else:\n",
    "    print(\"Morphological analysis failed.\")\n",
    "\n",
    "# graphviz.Graph('morphological_analysis_ja')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
